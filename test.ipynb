{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca190bb8-2ef8-4db8-a841-6df3c9eb7440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import tokenizers\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_cosine_schedule_with_warmup, DataCollatorWithPadding\n",
    "import cupy as cp\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "%env TOKENIZERS_PARALLELISM=false\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b769242f-e148-48b3-9dd0-42d9ddf04c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    print_freq = 3000\n",
    "    num_workers = 4\n",
    "    uns_model = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "    sup_model = \"xlm-roberta-base\"\n",
    "    uns_tokenizer = AutoTokenizer.from_pretrained(uns_model)\n",
    "    sup_tokenizer = AutoTokenizer.from_pretrained(sup_model)\n",
    "    gradient_checkpointing = False\n",
    "    batch_size = 32\n",
    "    n_folds = 5\n",
    "    top_n = 1000\n",
    "    seed = 42\n",
    "    threshold = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f06ab83-ceaf-4b45-91e8-f5449763b269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(cfg):\n",
    "    topics = pd.read_csv('/root/autodl-tmp/topics.csv')\n",
    "    content = pd.read_csv('/root/autodl-tmp/content.csv')\n",
    "    sample_submission = pd.read_csv('/root/autodl-tmp/sample_submission.csv')\n",
    "    # Merge topics with sample submission to only infer test topics\n",
    "    topics = topics.merge(sample_submission, how = 'inner', left_on = 'id', right_on = 'topic_id')\n",
    "    # Fillna titles\n",
    "    topics['title'].fillna(\"\", inplace = True)\n",
    "    content['title'].fillna(\"\", inplace = True)\n",
    "    # Sort by title length to make inference faster\n",
    "    topics['length'] = topics['title'].apply(lambda x: len(x))\n",
    "    content['length'] = content['title'].apply(lambda x: len(x))\n",
    "    topics.sort_values('length', inplace = True)\n",
    "    content.sort_values('length', inplace = True)\n",
    "    # Drop cols\n",
    "    topics.drop(['description', 'channel', 'category', 'level', 'language', 'parent', 'has_content', 'length', 'topic_id', 'content_ids'], axis = 1, inplace = True)\n",
    "    content.drop(['description', 'kind', 'language', 'text', 'copyright_holder', 'license', 'length'], axis = 1, inplace = True)\n",
    "    # Reset index\n",
    "    topics.reset_index(drop = True, inplace = True)\n",
    "    content.reset_index(drop = True, inplace = True)\n",
    "    print(' ')\n",
    "    print('-' * 50)\n",
    "    print(f\"topics.shape: {topics.shape}\")\n",
    "    print(f\"content.shape: {content.shape}\")\n",
    "    return topics, content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80779dd3-8dc1-4305-a623-6c0823f79592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inference_set(topics, content, cfg):\n",
    "    # Create lists for training\n",
    "    topics_ids = []\n",
    "    content_ids = []\n",
    "    title1 = []\n",
    "    title2 = []\n",
    "    # Iterate over each topic\n",
    "    for k in tqdm(range(len(topics))):\n",
    "        row = topics.iloc[k]\n",
    "        topics_id = row['id']\n",
    "        topics_title = row['title']\n",
    "        content_title = row['title']\n",
    "        topics_ids.append(topics_id)\n",
    "        content_ids.append(content_title)\n",
    "        title1.append(topics_title)\n",
    "        title2.append(content_title)\n",
    "    # Build training dataset\n",
    "    test = pd.DataFrame(\n",
    "        {'topics_ids': topics_ids, \n",
    "         'content_ids': content_ids, \n",
    "         'title1': title1, \n",
    "         'title2': title2\n",
    "        }\n",
    "    )\n",
    "    # Release memory\n",
    "    del topics_ids, content_ids, title1, title2\n",
    "    gc.collect()\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ffe996-123c-46c8-83c8-e63c66b099cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test(test):\n",
    "    test['title1'].fillna(\"Title does not exist\", inplace = True)\n",
    "    test['title2'].fillna(\"Title does not exist\", inplace = True)\n",
    "    # Create feature column\n",
    "    test['text'] = test['title1'] + '[SEP]' + test['title2']\n",
    "    # Drop titles\n",
    "    test.drop(['title1', 'title2'], axis = 1, inplace = True)\n",
    "    # Sort so inference is faster\n",
    "    test['length'] = test['text'].apply(lambda x: len(x))\n",
    "    test.sort_values('length', inplace = True)\n",
    "    test.drop(['length'], axis = 1, inplace = True)\n",
    "    test.reset_index(drop = True, inplace = True)\n",
    "    gc.collect()\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec423437-e332-4a74-8b21-f38aa90672ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_fn(test_loader, model, device):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(test_loader, total = len(test_loader))\n",
    "    for inputs in tk0:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        preds.append(y_preds.sigmoid().squeeze().to('cpu').numpy().reshape(-1))\n",
    "    predictions = np.concatenate(preds)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0de17cc1-eb9d-4356-80a7-10c6448bc30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(test, cfg):\n",
    "    # Create dataset and loader\n",
    "    test_dataset = sup_dataset(test, cfg)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size = cfg.batch_size, \n",
    "        shuffle = False, \n",
    "        collate_fn = DataCollatorWithPadding(tokenizer = cfg.sup_tokenizer, padding = 'longest'),\n",
    "        num_workers = cfg.num_workers, \n",
    "        pin_memory = True, \n",
    "        drop_last = False\n",
    "    )\n",
    "    # Get model\n",
    "    model = custom_model(cfg)\n",
    "    # Load weights\n",
    "    state = torch.load(\"/root/xlm-roberta-base_fold0_42.pth\", map_location = torch.device('cpu'))\n",
    "    model.load_state_dict(state['model'])\n",
    "    prediction = inference_fn(test_loader, model, device)\n",
    "    # Release memory\n",
    "    torch.cuda.empty_cache()\n",
    "    del test_dataset, test_loader, model, state\n",
    "    gc.collect()\n",
    "    # Use threshold\n",
    "    test['predictions'] = np.where(prediction > cfg.threshold, 1, 0)\n",
    "    test1 = test[test['predictions'] == 1]\n",
    "    test1 = test1.groupby(['topics_ids'])['content_ids'].unique().reset_index()\n",
    "    test1['content_ids'] = test1['content_ids'].apply(lambda x: ' '.join(x))\n",
    "    test1.columns = ['topic_id', 'content_ids']\n",
    "    test0 = pd.Series(test['topics_ids'].unique())\n",
    "    test0 = test0[~test0.isin(test1['topic_id'])]\n",
    "    test0 = pd.DataFrame({'topic_id': test0.values, 'content_ids': \"\"})\n",
    "    test_r = pd.concat([test1, test0], axis = 0, ignore_index = True)\n",
    "    test_r.to_csv('submission.csv', index = False)\n",
    "    return test_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f793f526-7950-4f1b-a9c8-55b7c25c95e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "topics.shape: (5, 2)\n",
      "content.shape: (154047, 2)\n"
     ]
    }
   ],
   "source": [
    "topics, content = read_data(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f458df41-668c-4001-a8f5-cbfb0303a7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(               id                                              title\n",
       " 0  t_00069b63a70a                                        Transcripts\n",
       " 1  t_00004da3a1b2                         Откриването на резисторите\n",
       " 2  t_4054df11a74e                     Flow Charts: Logical Thinking?\n",
       " 3  t_00068291e9a4                    Entradas e saídas de uma função\n",
       " 4  t_0006d41a73a8  Графики на експоненциални функции (Алгебра 2 н...,\n",
       "                                                             title\n",
       " id                                                               \n",
       " c_77105b4b84cc                                                   \n",
       " c_77574ef20c1f                                                   \n",
       " c_200ae87baf4d                                                   \n",
       " c_87e171afe50b                                                   \n",
       " c_3c070b63a944                                                   \n",
       " ...                                                           ...\n",
       " c_eae464c625ea  TI-AIE: Perspective on leadership: building a ...\n",
       " c_e92281698de8  ملخص الوحدة الثانية ( المكانيكا ) لمادة الفيزي...\n",
       " c_88f85461d72a  Actividad 1 - Valoramos la importancia de la a...\n",
       " c_ee7616e33ff1  11.3D: Harmful Effects Associated with Abnorma...\n",
       " c_0da37de9efb1  \"অনুশীলনীঃ ক. একটি কোণের বিপ্রতীপ কোণ চিহ্নিত ...\n",
       " \n",
       " [154047 rows x 1 columns])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics,content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb943f59-0b4c-432a-ad8b-0e9528400233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e8d4ab3d6647f685ea075cadda678b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = build_inference_set(topics, content, CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1cb78f3e-6f41-4026-ae0d-ac576ba1287d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topics_ids</th>\n",
       "      <th>content_ids</th>\n",
       "      <th>title1</th>\n",
       "      <th>title2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_00069b63a70a</td>\n",
       "      <td>Transcripts</td>\n",
       "      <td>Transcripts</td>\n",
       "      <td>Transcripts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>Откриването на резисторите</td>\n",
       "      <td>Откриването на резисторите</td>\n",
       "      <td>Откриването на резисторите</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_4054df11a74e</td>\n",
       "      <td>Flow Charts: Logical Thinking?</td>\n",
       "      <td>Flow Charts: Logical Thinking?</td>\n",
       "      <td>Flow Charts: Logical Thinking?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_00068291e9a4</td>\n",
       "      <td>Entradas e saídas de uma função</td>\n",
       "      <td>Entradas e saídas de uma função</td>\n",
       "      <td>Entradas e saídas de uma função</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_0006d41a73a8</td>\n",
       "      <td>Графики на експоненциални функции (Алгебра 2 н...</td>\n",
       "      <td>Графики на експоненциални функции (Алгебра 2 н...</td>\n",
       "      <td>Графики на експоненциални функции (Алгебра 2 н...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       topics_ids                                        content_ids  \\\n",
       "0  t_00069b63a70a                                        Transcripts   \n",
       "1  t_00004da3a1b2                         Откриването на резисторите   \n",
       "2  t_4054df11a74e                     Flow Charts: Logical Thinking?   \n",
       "3  t_00068291e9a4                    Entradas e saídas de uma função   \n",
       "4  t_0006d41a73a8  Графики на експоненциални функции (Алгебра 2 н...   \n",
       "\n",
       "                                              title1  \\\n",
       "0                                        Transcripts   \n",
       "1                         Откриването на резисторите   \n",
       "2                     Flow Charts: Logical Thinking?   \n",
       "3                    Entradas e saídas de uma função   \n",
       "4  Графики на експоненциални функции (Алгебра 2 н...   \n",
       "\n",
       "                                              title2  \n",
       "0                                        Transcripts  \n",
       "1                         Откриването на резисторите  \n",
       "2                     Flow Charts: Logical Thinking?  \n",
       "3                    Entradas e saídas de uma função  \n",
       "4  Графики на експоненциални функции (Алгебра 2 н...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b9c60f7-4e18-4969-a8eb-92bcb490615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = preprocess_test(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f2f796c-5217-45b1-a815-35d86855cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sup_dataset(Dataset):\n",
    "    def __init__(self, df, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['text'].values\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_sup_input(self.texts[item], self.cfg)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4830975e-3580-48d8-8e1a-3ecc037e0329",
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_model(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.config = AutoConfig.from_pretrained(cfg.sup_model, output_hidden_states = True)\n",
    "        self.config.hidden_dropout = 0.0\n",
    "        self.config.hidden_dropout_prob = 0.0\n",
    "        self.config.attention_dropout = 0.0\n",
    "        self.config.attention_probs_dropout_prob = 0.0\n",
    "        self.model = AutoModel.from_pretrained(cfg.sup_model, config = self.config)\n",
    "        if self.cfg.gradient_checkpointing:\n",
    "            self.model.gradient_checkpointing_enable()\n",
    "        self.pool = MeanPooling()\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 1)\n",
    "        self._init_weights(self.fc)\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        feature = self.pool(last_hidden_state, inputs['attention_mask'])\n",
    "        return feature\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        output = self.fc(feature)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14bb552b-c36c-4603-85b9-f0b9281e5de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9498b4cb-f5df-4b9c-94b1-0bb865ccea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sup_input(text, cfg):\n",
    "    inputs = cfg.sup_tokenizer.encode_plus(\n",
    "        text, \n",
    "        return_tensors = None, \n",
    "        add_special_tokens = True, \n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype = torch.long)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "13f71ce7-b70e-4975-b4b5-e149cfcb5703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20dbee4e2574c0ba51fe7f80aa349ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>content_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>Откриването на резисторите</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_00068291e9a4</td>\n",
       "      <td>Entradas e saídas de uma função</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_0006d41a73a8</td>\n",
       "      <td>Графики на експоненциални функции (Алгебра 2 н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_4054df11a74e</td>\n",
       "      <td>Flow Charts: Logical Thinking?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_00069b63a70a</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic_id                                        content_ids\n",
       "0  t_00004da3a1b2                         Откриването на резисторите\n",
       "1  t_00068291e9a4                    Entradas e saídas de uma função\n",
       "2  t_0006d41a73a8  Графики на експоненциални функции (Алгебра 2 н...\n",
       "3  t_4054df11a74e                     Flow Charts: Logical Thinking?\n",
       "4  t_00069b63a70a                                                   "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_r = inference(test, CFG)\n",
    "test_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbc7d55-ab6c-4e65-afda-545c0f707fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
